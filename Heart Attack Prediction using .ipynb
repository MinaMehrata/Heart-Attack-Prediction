{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This Notebook is divided in 5 sections\n1. Importing the Dataset and all the necessary libraries.\n2. visualization of the data\n3. Preprocessing the data\n4. Training of the data\n5. Conclusion."},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing the Dataset and libraries."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nfrom random import shuffle\n\nimport keras\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler , LabelEncoder\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\nfrom sklearn.metrics import accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Visualizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True,cmap='seismic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=np.asarray(df[[\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\"]])\ny=np.asarray(df[[\"target\"]])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Pre-Processing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm = StandardScaler()\nx_train = norm.fit_transform(x_train)\nx_test = norm.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Training of the dataset"},{"metadata":{},"cell_type":"markdown","source":"1. ***Logistic Regression***"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nhistory_2 = lr.fit(x_train,y_train) \n\n\ny_pred_2 = lr.predict(x_test)\ny_pred_2 = (y_pred_2 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_2)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_2))\n\n\npred_2 = 100*accuracy_score(y_test,y_pred_2)\n\nprint('percentage Accuracy : ',pred_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. ***Random Forest***"},{"metadata":{"trusted":true},"cell_type":"code","source":"rnf = RandomForestClassifier(n_estimators=100,random_state=0,max_depth=5)\nhistory_3 = rnf.fit(x_train,y_train)\n\n\ny_pred_3 = rnf.predict(x_test)\ny_pred_3 = (y_pred_3 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_3)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_3))\n\npred_3 = 100*accuracy_score(y_test,y_pred_3)\n\nprint('percentage Accuracy : ',pred_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. ***Decision Tree***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\nhistory_4 = dt.fit(x_train, y_train)\n\n\ny_pred_4 = dt.predict(x_test)\ny_pred_4 = (y_pred_4 > 0.5)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_4)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_4))\n\npred_4 = 100*accuracy_score(y_test,y_pred_4)\n\nprint('percentage Accuracy : ',pred_4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"height = [pred_2,pred_3,pred_4]\nbars = ('Logistic Reg.','Random Forest',' Decision Tree')\ny_pos = np.arange(len(bars))\n\nplt.bar(y_pos, height, color=['green', 'blue','red'])\nplt.xticks(y_pos, bars)\nplt.ylabel(\"acurracy%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(max(height))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, we can conclude that Random Forest has work best in this case with accuracy being ***86.84%***\n\nHope you enjoyed the Notebook!!!\n\n***Thank you***"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}